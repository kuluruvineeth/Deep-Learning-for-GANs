{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample with Convolutional Neural Networks\n",
    "* Two common types of layers that can be used in the generator model are : \n",
    "    * **upsample layer** : that simply doubles the dimensions of the input.\n",
    "    * **transpose convolutional layer** : that performs an inverse convolution operation.\n",
    "    \n",
    "* A simple version of an unpooling or opposite pooling layer is called an **upsampling layer**.\n",
    "\n",
    "Both of these layers can be used on a GAN to perform the required upsampling operation to transform a small input into a large image output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Worked Example Using the *UpSampling2D* Layer\n",
    "* The simplest way to upsample an input is to double each row and column.\n",
    "* It can be added to a convolutional neural network and repeats the rows and columns provided as input in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "up_sampling2d_1 (UpSampling2 (None, 4, 4, 1)           0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[1. 1. 2. 2.]\n",
      " [1. 1. 2. 2.]\n",
      " [3. 3. 4. 4.]\n",
      " [3. 3. 4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# example of using the upsampling layer\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import UpSampling2D\n",
    "\n",
    "# define input data\n",
    "X = asarray([[1,2],[3,4]])\n",
    "\n",
    "# show input data for context\n",
    "print(X)\n",
    "\n",
    "# reshape input data into one sample a sample with a channel\n",
    "X = X.reshape((1,2,2,1)) # samples,rows,columns,channels\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(UpSampling2D(input_shape=(2,2,1)))\n",
    "\n",
    "# summarize the model\n",
    "model.summary()\n",
    "\n",
    "# make a prediction with the model\n",
    "yhat = model.predict(X)\n",
    "\n",
    "# reshape output to remove channel to make printing easier\n",
    "yhat = yhat.reshape((4,4))\n",
    "\n",
    "# summarize output\n",
    "print(yhat)\n",
    "\n",
    "# the layer has no parameters or model weights,because it is not learning anything,it is just doubling the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Generator Model With the *UpSampling2D* Layer\n",
    "* To be useful in a GAN,each *UpSampling2D* layer must be followed by a *Conv2D* layer that will learn to interpret the doubled input and be trained to translate it into meaningful detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3200)              323200    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 10, 10, 1)         1153      \n",
      "=================================================================\n",
      "Total params: 324,353\n",
      "Trainable params: 324,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of using upsampling in a simple generator model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "\n",
    "# define input shape,output enough activations for 128 5x5 image\n",
    "model.add(Dense(128 * 5 * 5,input_dim=100))\n",
    "# reshape vector of activations into 128 feature maps with 5x5\n",
    "model.add(Reshape((5,5,128)))\n",
    "# double input from 128 5x5 to 1 10x10 feature map\n",
    "model.add(UpSampling2D())\n",
    "# fill in detail in the upsampled feature maps and output a single image\n",
    "model.add(Conv2D(1,(3,3),padding='same'))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Worked Example Using the *Conv2DTranspose* Layer\n",
    "* The Conv2DTranspose both upsamples and performs a convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose (Conv2DTran (None, 4, 4, 1)           2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[1. 0. 2. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [3. 0. 4. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# example of using the transpose convolutional layer\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2DTranspose\n",
    "\n",
    "# define input data\n",
    "X = asarray([[1,2],[3,4]])\n",
    "# show input data for context\n",
    "print(X)\n",
    "\n",
    "# reshape input data into one sample a sample with a channel\n",
    "X = X.reshape((1,2,2,1))\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv2DTranspose(1,(1,1),strides=(2,2),input_shape=(2,2,1)))\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# define weights that they do nothing\n",
    "weights = [asarray([[[[1]]]]),asarray([0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# make a prediction with the model\n",
    "yhat = model.predict(X)\n",
    "# reshape output to remove channel to make printing easier\n",
    "yhat = yhat.reshape((4,4))\n",
    "# summarize output\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
